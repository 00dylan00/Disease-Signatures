{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" iLINCS Numbers\n",
    "\n",
    "Here the aim is to come up with preliminary numbers for the iLINCS project - \n",
    "to show how much data we have.\n",
    "\n",
    "Structure:\n",
    "    a) Load signature data\n",
    "    b) Numbers for datasets\n",
    "    c) Numbers for factors\n",
    "    d) Numbers for conditions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Load signature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 14:56:11,044 - INFO - Starting to Get All Signatures: \n",
      "2023-12-19 14:56:35,659 - INFO - Finished Getting All Signatures. Total time taken: 24.6154 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"iLINCS\n",
    "\n",
    "The exercise here is to quantify HOW many diseases are there for which we have \"disease\" signatures\n",
    "\n",
    "Structure:\n",
    "    1. Imports, Variables, Functions\n",
    "    2. Retrieve MeSH terms\n",
    "    3. Retrieve Signature Datasets\n",
    "    4. Maps MeSH terms to Signatures\n",
    "    5. Plot Results\n",
    "\"\"\"\n",
    "\n",
    "# 1. Imports, Variables, Functions\n",
    "# imports\n",
    "import requests, json, re\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Bio import Entrez\n",
    "import logging\n",
    "import time\n",
    "from collections import Counter\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "\n",
    "# variables\n",
    "Entrez.email = \"dylandaltonsub@gmail.com\"\n",
    "base_url = \"http://www.ilincs.org/api\"\n",
    "doi_data_path = \"../data/DiseaseOntology/doid.obo\"\n",
    "mesh_file_path = \"../data/MeSH/desc2023.xml\"\n",
    "d_dataset_2_mesh = dict()\n",
    "d_signature_2_mesh = dict()\n",
    "d_mesh_symbol_2_term = dict()\n",
    "filter_criteria = lambda s: (s[\"factor\"] == \"disease.state\") and (\n",
    "    \"normal\" in s[\"level2\"] or \"control\" in s[\"level2\"] or \"healthy\" in s[\"level2\"]\n",
    ")\n",
    "\n",
    "\n",
    "# functions\n",
    "def fetch_disease_signatures(factor):\n",
    "    \"\"\"Fetch Disease Signatures\"\"\"\n",
    "\n",
    "    # Construct the filtering JSON based on provided example\n",
    "    # filter_json = {\n",
    "    #     \"where\": {\n",
    "    #         \"factor\": factor,\n",
    "    #         #\"baseline\": baseline\n",
    "    #     }\n",
    "    # }\n",
    "    # filter_str = json.dumps(filter_json)\n",
    "\n",
    "    endpoint = f\"{base_url}/SignatureMeta\"\n",
    "    # response = requests.get(endpoint, params={\"filter\": filter_str})\n",
    "    response = requests.get(endpoint)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # assuming the response is in JSON format\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return []\n",
    "\n",
    "\n",
    "def extract_disease_names_from_obo(file_path):\n",
    "    \"\"\"\n",
    "    Extracts disease names from an OBO formatted file.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the OBO file.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of disease names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open and read the content of the OBO file\n",
    "    with open(file_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # The OBO format divides entries using '[Term]'. We split the content based on this to get individual entries.\n",
    "    terms = content.split(\"[Term]\")\n",
    "\n",
    "    disease_names = []  # List to store extracted disease names\n",
    "\n",
    "    # Iterate over each term/entry\n",
    "    for term in terms:\n",
    "        # Use a regular expression to search for the line that starts with 'name: '\n",
    "        # This line contains the name of the disease.\n",
    "        match = re.search(r\"name: (.+)\", term)\n",
    "\n",
    "        # If a match is found (i.e., the term has a name), extract it and add to the list\n",
    "        if match:\n",
    "            disease_name = match.group(\n",
    "                1\n",
    "            )  # The actual name is captured in the first group of the regex\n",
    "            disease_names.append(disease_name)\n",
    "\n",
    "    return disease_names\n",
    "\n",
    "\n",
    "def parse_mesh_data(file_path):\n",
    "    \"\"\"Parse MeSH XML data and extract disease terms.\"\"\"\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract disease terms\n",
    "    disease_terms = []\n",
    "    for descriptor in root.findall(\"DescriptorRecord\"):\n",
    "        term = descriptor.find(\"DescriptorName/String\").text\n",
    "        disease_terms.append(term)\n",
    "\n",
    "    return disease_terms, None\n",
    "\n",
    "\n",
    "def parse_mesh_data(file_path):\n",
    "    \"\"\"Parse MeSH XML data and extract disease terms.\n",
    "\n",
    "    Retrieve the Botom-Most disease terms which contain the most specific\n",
    "    information for a disease.\n",
    "\n",
    "    Parameters:\n",
    "        file_path: str()\n",
    "\n",
    "    Return:\n",
    "        disease_terms: list()\n",
    "        list_tree_numbers: list()\"\"\"\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract disease terms\n",
    "    disease_terms = list()\n",
    "    list_tree_numbers = list()\n",
    "    for descriptor in root.findall(\"DescriptorRecord\"):\n",
    "        # Check if the term is under the category of diseases\n",
    "        tree_numbers = descriptor.findall(\"TreeNumberList/TreeNumber\")\n",
    "        for tree_number in tree_numbers:\n",
    "            # This is a basic check for TreeNumbers starting with 'C' which usually denotes diseases in MeSH\n",
    "            # You might need to adjust this based on the specific structure of your XML file\n",
    "            if tree_number.text.startswith(\"C\"):\n",
    "                list_tree_numbers.append(tree_number.text)\n",
    "                term = descriptor.find(\"DescriptorName/String\").text\n",
    "                disease_terms.append(term)\n",
    "                break  # Break after adding the term to avoid duplicates\n",
    "\n",
    "    return disease_terms, list_tree_numbers\n",
    "\n",
    "\n",
    "def extract_pmid_from_publink(publink):\n",
    "    \"\"\"Extract the PubMed ID from the provided publink.\"\"\"\n",
    "    pmid_match = re.search(r\"term=(\\d+)\\[UID\\]\", publink)\n",
    "    if pmid_match:\n",
    "        return pmid_match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_pmid_from_geo_via_eutils(geo_id):\n",
    "    # Use elink to establish links between GEO and PubMed databases\n",
    "    handle = Entrez.elink(dbfrom=\"gds\", db=\"pubmed\", id=geo_id[3:])\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    # Extract the PMID from the linked records\n",
    "    # if it has LinkSetDb report else return None\n",
    "    if len(record[0][\"LinkSetDb\"]) > 0:\n",
    "        return record[0][\"LinkSetDb\"][0][\"Link\"][0][\"Id\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_disease_signatures():\n",
    "    \"\"\"Fetch Disease Signatures\"\"\"\n",
    "\n",
    "    # Construct the filtering JSON based on provided example\n",
    "    # filter_json = {\n",
    "    #     \"where\": {\n",
    "    #         \"factor\": factor,\n",
    "    #         #\"baseline\": baseline\n",
    "    #     }\n",
    "    # }\n",
    "    # filter_str = json.dumps(filter_json)\n",
    "\n",
    "    endpoint = f\"{base_url}/SignatureMeta\"\n",
    "    # response = requests.get(endpoint, params={\"filter\": filter_str})\n",
    "    response = requests.get(endpoint)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # assuming the response is in JSON format\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return []\n",
    "\n",
    "\n",
    "def fetch_dataset_metadata(dataset_id):\n",
    "    \"\"\"Fetch dataset metadata/description for a given dataset.\"\"\"\n",
    "    endpoint = f\"{base_url}/PublicDatasets/{dataset_id}\"\n",
    "    response = requests.get(endpoint)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # assuming the response is in JSON format\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_mesh_terms_from_pubmed(pmid):\n",
    "    \"\"\"Fetch MeSH terms for a given PubMed ID.\"\"\"\n",
    "    if not pmid:\n",
    "        return []\n",
    "\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "    params = {\"db\": \"pubmed\", \"id\": pmid, \"retmode\": \"xml\"}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching MeSH terms for PMID {pmid}: {response.text}\")\n",
    "        return []\n",
    "\n",
    "    # Parse the XML response to extract MeSH terms\n",
    "    root = ET.fromstring(response.text)\n",
    "    mesh_terms = [\n",
    "        descriptor.findtext(\"DescriptorName\")\n",
    "        for descriptor in root.findall(\".//MeshHeading\")\n",
    "    ]\n",
    "\n",
    "    # Parse the XML response to extract MeSH tree numbers\n",
    "    mesh_tree_numbers = list()\n",
    "    for descriptor in root.findall(\".//MeshHeading\"):\n",
    "        # Find the DescriptorName element and get its UI attribute\n",
    "        descriptor_ui = descriptor.find(\"DescriptorName\").get(\"UI\")\n",
    "        # Use the UI to find the corresponding TreeNumberList/TreeNumber elements\n",
    "        tree_numbers = root.findall(\n",
    "            f\".//DescriptorRecord[DescriptorUI='{descriptor_ui}']/TreeNumberList/TreeNumber\"\n",
    "        )\n",
    "        mesh_tree_numbers.extend([tree_number.text for tree_number in tree_numbers])\n",
    "\n",
    "    return mesh_terms, mesh_tree_numbers\n",
    "\n",
    "\n",
    "def extract_pmid_from_publink(publink):\n",
    "    \"\"\"Extract the PubMed ID from the provided publink.\"\"\"\n",
    "    pmid_match = re.search(r\"term=(\\d+)\\[UID\\]\", publink)\n",
    "    if pmid_match:\n",
    "        return pmid_match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_mesh_term_tree_number_mapping(mesh_xml_file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Build a mapping of MeSH terms to their tree numbers from the MeSH XML file.\n",
    "\n",
    "    Parameters:\n",
    "    - mesh_xml_file_path (str): The file path to the MeSH XML file.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary where keys are MeSH terms and values are lists of associated tree numbers.\n",
    "    \"\"\"\n",
    "    tree = ET.parse(mesh_xml_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    mesh_term_2_symbol = dict()\n",
    "    mesh_symbol_2_term = dict()\n",
    "    for descriptor in root.findall(\"DescriptorRecord\"):\n",
    "        term = descriptor.find(\"DescriptorName/String\").text\n",
    "        tree_numbers = [\n",
    "            tree_number.text\n",
    "            for tree_number in descriptor.findall(\"TreeNumberList/TreeNumber\")\n",
    "        ]\n",
    "        for tree_number in tree_numbers:\n",
    "            mesh_symbol_2_term[tree_number] = term\n",
    "        mesh_term_2_symbol[term] = tree_numbers\n",
    "\n",
    "    return mesh_term_2_symbol, mesh_symbol_2_term\n",
    "\n",
    "\n",
    "# 2. Retrieve MeSH terms\n",
    "# retrieve disease terms and store in dictionary\n",
    "disease_names_mesh, symbol_mesh = parse_mesh_data(file_path=mesh_file_path)\n",
    "d_mesh_symbol_2_term = dict(zip(symbol_mesh, disease_names_mesh))\n",
    "\n",
    "# 3. Retrieve Signature Datasets\n",
    "start_time = time.time()\n",
    "logging.info(\"Starting to Get All Signatures: \")\n",
    "\n",
    "# get all signatures\n",
    "signatures = fetch_disease_signatures()\n",
    "\n",
    "end_time = time.time()\n",
    "logging.info(\n",
    "    f\"Finished Getting All Signatures. Total time taken: %.4f seconds\"\n",
    "    % (end_time - start_time)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Numbers for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Nº of datasets!\n",
    "def sort_dict(d_data):\n",
    "    # Alternative way to sort the dictionary by values in descending order without using lambda\n",
    "    x = sorted(d_data, key=d_data.get, reverse=True)\n",
    "    y = [d_data[key] for key in x]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# filter Data\n",
    "data_plot = Counter([s[\"datasetid\"] for s in signatures if s[\"libraryid\"] == \"LIB_1\"])\n",
    "\n",
    "print(f\"Nº of Unique Datasets: {len(set(data_plot))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for plot\n",
    "x, y = sort_dict(data_plot)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "# Calculate relative heights (normalized to the range [0, 1])\n",
    "relative_heights = y[:10] / np.max(y[:10])\n",
    "\n",
    "# Choose a colormap\n",
    "cmap = cm.get_cmap(\"Blues\")\n",
    "\n",
    "# Creating the bar plot with gradient effect\n",
    "bars = plt.bar(\n",
    "    x[:10], y[:10], color=[cmap(height) for height in relative_heights], zorder=3\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=80)\n",
    "plt.title(\n",
    "    \"Nº of Sigantures per Dataset - TOP 10\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    yval_perc = yval / 9087 * 100\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        yval,\n",
    "        f\"{yval/8067*100:.2f}%\",\n",
    "        verticalalignment=\"bottom\",\n",
    "        ha=\"center\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Optional: Adding grid lines\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, zorder=-2)\n",
    "plt.savefig(\n",
    "    \"../results/figures/iLINCS/numbers/n_datasets.png\", dpi=300, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Numbers for factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "# plot Nº of datasets!\n",
    "def sort_dict(d_data):\n",
    "    # Alternative way to sort the dictionary by values in descending order without using lambda\n",
    "    x = sorted(d_data, key=d_data.get, reverse=True)\n",
    "    y = [d_data[key] for key in x]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Define Data of interest\n",
    "data_plot = Counter([s[\"factor\"] for s in signatures if s[\"libraryid\"] == \"LIB_1\"])\n",
    "\n",
    "print(f\"Nº of Unique Factors: {len(set(data_plot))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define values\n",
    "x, y = sort_dict(data_plot)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "\n",
    "# Calculate relative heights (normalized to the range [0, 1])\n",
    "relative_heights = y[:10] / np.max(y[:10])\n",
    "\n",
    "# Choose a colormap\n",
    "cmap = cm.get_cmap(\n",
    "    \"Greens\"\n",
    ")  # You can choose different colormaps like 'Reds', 'Greens', etc.\n",
    "\n",
    "# Creating the bar plot with gradient effect\n",
    "bars = plt.bar(\n",
    "    x[:10], y[:10], color=[cmap(height) for height in relative_heights], zorder=3\n",
    ")\n",
    "\n",
    "\n",
    "plt.xticks(rotation=80)\n",
    "plt.title(\n",
    "    \"Nº of Sigantures per Factor - TOP 10\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    yval_perc = yval / 9087 * 100\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        yval,\n",
    "        f\"{yval/8067*100:.2f}%\",\n",
    "        verticalalignment=\"bottom\",\n",
    "        ha=\"center\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Optional: Adding grid lines\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, zorder=-2)\n",
    "plt.savefig(\n",
    "    \"../results/figures/iLINCS/numbers/n_factors.png\", dpi=300, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Numbers for conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "# plot Nº of datasets!\n",
    "def sort_dict(d_data):\n",
    "    # Alternative way to sort the dictionary by values in descending order without using lambda\n",
    "    x = sorted(d_data, key=d_data.get, reverse=True)\n",
    "    y = [d_data[key] for key in x]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Define Data of interest\n",
    "data_plot_ = [s[\"level1\"] for s in signatures if s[\"libraryid\"] == \"LIB_1\"]\n",
    "data_plot_.extend([s[\"level2\"] for s in signatures if s[\"libraryid\"] == \"LIB_1\"])\n",
    "\n",
    "print(f\"Nº of Unique Conditions: {len(set(data_plot))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot = Counter(data_plot_)\n",
    "\n",
    "# Define values\n",
    "x, y = sort_dict(data_plot)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "\n",
    "# Calculate relative heights (normalized to the range [0, 1])\n",
    "relative_heights = y[:10] / np.max(y[:10])\n",
    "\n",
    "# Choose a colormap\n",
    "cmap = cm.get_cmap(\n",
    "    \"Oranges\"\n",
    ")  # You can choose different colormaps like 'Reds', 'Greens', etc.\n",
    "\n",
    "# Creating the bar plot with gradient effect\n",
    "bars = plt.bar(\n",
    "    x[:10], y[:10], color=[cmap(height) for height in relative_heights], zorder=3\n",
    ")\n",
    "\n",
    "\n",
    "plt.xticks(rotation=80)\n",
    "plt.title(\n",
    "    \"Nº of Sigantures per Condition - TOP 10\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    yval_perc = yval / 9087 * 100\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        yval,\n",
    "        f\"{yval/8067*100:.2f}%\",\n",
    "        verticalalignment=\"bottom\",\n",
    "        ha=\"center\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Optional: Adding grid lines\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, zorder=-2)\n",
    "plt.savefig(\n",
    "    \"../results/figures/iLINCS/numbers/n_conditions.png\", dpi=300, bbox_inches=\"tight\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disease_sig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
